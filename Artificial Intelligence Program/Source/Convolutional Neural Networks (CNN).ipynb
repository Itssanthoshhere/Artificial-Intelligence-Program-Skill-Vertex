{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c565a99",
   "metadata": {},
   "source": [
    "### ğŸ§  Deep Learning Made Easy: A Beginnerâ€™s Guide to CNNs with TensorFlow ğŸ§ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20854e",
   "metadata": {},
   "source": [
    "#### 1. Installing Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd41db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras\n",
    "# pip install tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13579b2",
   "metadata": {},
   "source": [
    "#### 2. Introduction to TensorFlow:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fb6d7",
   "metadata": {},
   "source": [
    "ğ—§ğ—²ğ—»ğ˜€ğ—¼ğ—¿ğ—³ğ—¹ğ—¼ğ˜„ is basically used for performing mathematical opertions like numpy but it is for high computstion part. It utilizes GPUs that is graphical processing unit for faster computation and efficiently. It will compute the gradients by building the symbolic type of graphs automatically to it. so, it is very, very suitable for unstable type of expressions as it first observes them numerically and then computes them with the more suitable algorithms. This is the main tenserflow that it is also a google product which is one of the most famous deep learning tools used in the area of machine learning and deep neural network. So, basically it can run your multiple CPUs and GPUs. It can also work with CPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4963ef9",
   "metadata": {},
   "source": [
    "#### 3. Code Walkthrough:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c1da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308f777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "\n",
    "# ğ—™ğ—¹ğ—®ğ˜ğ˜ğ—²ğ—» it converts the metrics format of the layer into the flat layer so we can easily transfer the data to the output layer. \n",
    "from tensorflow.keras.layers import Flatten \n",
    "\n",
    "# ğ——ğ—¿ğ—¼ğ—½ğ—¼ğ˜‚ğ˜ it is used to drop the unneccessary features in our data set.\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cea23",
   "metadata": {},
   "source": [
    "ğ—§ğ—²ğ—»ğ˜€ğ—¼ğ—¿ğ—™ğ—¹ğ—¼ğ˜„ ğ—®ğ—»ğ—± ğ—ğ—²ğ—¿ğ—®ğ˜€ ğ—œğ—ºğ—½ğ—¼ğ—¿ğ˜ğ˜€: Import necessary modules for creating and training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326033f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2],1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2],1))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c9d89",
   "metadata": {},
   "source": [
    "ğ—Ÿğ—¼ğ—®ğ—±ğ—¶ğ—»ğ—´ ğ—®ğ—»ğ—± ğ—£ğ—¿ğ—²ğ—½ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—»ğ—´ ğ——ğ—®ğ˜ğ—®:\n",
    "   - The MNIST dataset, a collection of handwritten digits, is loaded.\n",
    "   - Data is reshaped to include a channel dimension (1 for grayscale images).\n",
    "   - Pixel values are normalized to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1481daf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1568 - accuracy: 0.9531\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0538 - accuracy: 0.9837\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0357 - accuracy: 0.9891\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0242 - accuracy: 0.9927\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0170 - accuracy: 0.9946\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0072 - accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0052 - accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b65427d410>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Convolution Layer\n",
    "model.add(Conv2D(32,(3,3), activation = 'relu', input_shape = (28,28,1)))\n",
    "\n",
    "# Add Pooling Layer\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "# Add Fulling Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "\n",
    "# Add Output Layer\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b0e76",
   "metadata": {},
   "source": [
    "ğŒğ¨ğğğ¥ ğƒğğŸğ¢ğ§ğ¢ğ­ğ¢ğ¨ğ§ ğšğ§ğ ğ“ğ«ğšğ¢ğ§ğ¢ğ§ğ :\n",
    "   - ğ—–ğ—¼ğ—»ğ˜ƒğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—» ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Extracts features from the image.\n",
    "   - ğ—£ğ—¼ğ—¼ğ—¹ğ—¶ğ—»ğ—´ ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Reduces dimensionality, retaining essential features.\n",
    "   - ğ—™ğ—¹ğ—®ğ˜ğ˜ğ—²ğ—» ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Converts 2D matrices into 1D vectors for the dense layers.\n",
    "   - ğ——ğ—²ğ—»ğ˜€ğ—² ğ—Ÿğ—®ğ˜†ğ—²ğ—¿ğ˜€: Perform classification.\n",
    "   - ğ—¢ğ˜‚ğ˜ğ—½ğ˜‚ğ˜ ğ—Ÿğ—®ğ˜†ğ—²ğ—¿: Uses softmax to output probabilities for each class.\n",
    "   - ğ—–ğ—¼ğ—ºğ—½ğ—¶ğ—¹ğ—®ğ˜ğ—¶ğ—¼ğ—»: Configures the model for training with a loss function and optimizer.\n",
    "   - ğ—§ğ—¿ğ—®ğ—¶ğ—»ğ—¶ğ—»ğ—´: Fits the model to the training data over 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4246b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0601 - accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06007469445466995, 0.9855999946594238]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the Model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501a011",
   "metadata": {},
   "source": [
    "ğ—˜ğ˜ƒğ—®ğ—¹ğ˜‚ğ—®ğ˜ğ—¶ğ—¼ğ—»: Assesses model performance on the test dataset, reporting loss and accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff96547",
   "metadata": {},
   "source": [
    "This code and process illustrate how to create, train, and evaluate a CNN model using TensorFlow and Keras for image classification tasks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
